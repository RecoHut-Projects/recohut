{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets.movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Dataset\n",
    "> Implementation of MovieLens datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "from datetime import date\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "from recohut.datasets.base import Dataset, RatingDataset\n",
    "from recohut.utils.common_utils import download_url, extract_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML1m Rating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ML1mRatingDataset(RatingDataset, torch.utils.data.Dataset):\n",
    "    url = \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return 'ratings.dat'\n",
    "\n",
    "    def download(self):\n",
    "        path = download_url(self.url, self.raw_dir)\n",
    "        extract_zip(path, self.raw_dir)\n",
    "        from shutil import move, rmtree\n",
    "        move(osp.join(self.raw_dir, 'ml-1m', self.raw_file_names), self.raw_dir)\n",
    "        rmtree(osp.join(self.raw_dir, 'ml-1m'))\n",
    "        os.unlink(path)\n",
    "\n",
    "    def process(self):\n",
    "        data = pd.read_csv(self.raw_paths[0], sep='::', header=None, engine='python').to_numpy()[:, :3]\n",
    "        self.items = data[:, :2].astype(np.int) - 1  # -1 because ID begins from 1\n",
    "        self.targets = self.__preprocess_target(data[:, 2]).astype(np.float32)\n",
    "        self.field_dims = np.max(self.items, axis=0) + 1\n",
    "        self.user_field_idx = np.array((0, ), dtype=np.long)\n",
    "        self.item_field_idx = np.array((1,), dtype=np.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.items[index], self.targets[index]\n",
    "\n",
    "    def __preprocess_target(self, target):\n",
    "        # treat samples with a rating less than 3 as negative samples\n",
    "        target[target <= 3] = 0\n",
    "        target[target > 3] = 1\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "Extracting /content/ML1m/raw/ml-1m.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ds = ML1mRatingDataset(root='/content/ML1m', min_uc=10, min_sc=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML100k Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ML100kDataset(Dataset):\n",
    "    url = 'https://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        super().__init__(root)\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        return ['u1.base', 'u1.test', 'u4.test', 'allbut.pl', 'u.item', \n",
    "                'ua.test', 'u.occupation', 'u3.test', 'u5.base', 'ub.test', \n",
    "                'u2.test', 'u3.base', 'u.genre', 'u.data', 'u4.base', \n",
    "                'u5.test', 'u.info', 'README', 'ub.base', 'mku.sh', 'u2.base', \n",
    "                'u.user', 'ua.base']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def download(self):\n",
    "        path = download_url(self.url, self.raw_dir)\n",
    "        extract_zip(path, self.raw_dir)\n",
    "        from shutil import move, rmtree\n",
    "        file_names = os.listdir(osp.join(self.raw_dir, 'ml-100k'))   \n",
    "        for file_name in file_names:\n",
    "            move(osp.join(self.raw_dir, 'ml-100k', file_name), self.raw_dir)\n",
    "        rmtree(osp.join(self.raw_dir, 'ml-100k'))\n",
    "        os.unlink(path)\n",
    "\n",
    "    def process(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sparsh A.\n",
      "\n",
      "Last updated: 2021-12-21 09:41:25\n",
      "\n",
      "Compiler    : GCC 7.5.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.104+\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 2\n",
      "Architecture: 64bit\n",
      "\n",
      "google : 2.0.3\n",
      "numpy  : 1.19.5\n",
      "pandas : 1.1.5\n",
      "IPython: 5.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sparsh A.\" -m -iv -u -t -d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
