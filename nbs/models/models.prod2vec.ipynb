{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56WOhvufHqtI"
      },
      "outputs": [],
      "source": [
        "# default_exp models.prod2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLRjg-NsHqtO"
      },
      "source": [
        "# Prod2Vec\n",
        "> Implementation of Prod2vec model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TMU4CMXHqtR"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from nbdev.showdoc import *\n",
        "from fastcore.nb_imports import *\n",
        "from fastcore.test import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0klz0IeHqtS"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "from typing import List\n",
        "\n",
        "import logging\n",
        "import gensim\n",
        "import numpy as np\n",
        "import os\n",
        "from abc import ABC\n",
        "import ast"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prod2Vec"
      ],
      "metadata": {
        "id": "cE9gIYPvIaHq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSm05FSRHqtU"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class Prod2Vec(object):\n",
        "    \"\"\"\n",
        "    Implementation of the Prod2Vec skipgram model from\n",
        "    Grbovic Mihajlo, Vladan Radosavljevic, Nemanja Djuric, Narayan Bhamidipati, Jaikit Savla, Varun Bhagwan, and Doug Sharp.\n",
        "    \"E-commerce in your inbox: Product recommendations at scale.\"\n",
        "    In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,\n",
        "    pp. 1809-1818. ACM, 2015.\n",
        "    \"\"\"\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "    logger = logging.getLogger()\n",
        "\n",
        "    def __init__(self, min_count=2, negative=5, size=100, window=5, decay_alpha=0.9):\n",
        "        \"\"\"\n",
        "        :param min_count: (optional) the minimum item frequency. Items less frequent that min_count will be pruned\n",
        "        :param negative: (optional) the minimum negative samples\n",
        "        :param size: (optional) the size of the embeddings\n",
        "        :param window: (optional) the size of the context window\n",
        "        :param decay_alpha: (optional) the exponential decay factor used to discount the similarity scores for items\n",
        "                back in the user profile. Lower values mean higher discounting of past user interactions. Allows values in [0-1].\n",
        "        \"\"\"\n",
        "        super(Prod2Vec, self).__init__()\n",
        "        self.min_count = min_count\n",
        "        self.negative = negative\n",
        "        self.size = size\n",
        "        self.window = window\n",
        "        self.decay_alpha = decay_alpha\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'Prod2Vec(min_count={min_count}, ' \\\n",
        "               'size={size}, ' \\\n",
        "               'window={window}, ' \\\n",
        "               'decay_alpha={decay_alpha})'.format(**self.__dict__)\n",
        "\n",
        "    def fit(self, train_data):\n",
        "        self.model = gensim.models.Word2Vec(train_data,\n",
        "                                            min_count=self.min_count,\n",
        "                                            negative=self.negative,\n",
        "                                            window=self.window,\n",
        "                                            hs=1,\n",
        "                                            size=self.size,\n",
        "                                            sg=1,\n",
        "                                            workers=-1)\n",
        "        self.model.train(train_data, total_examples = self.model.corpus_count, \n",
        "                         epochs=10, report_delay=1)\n",
        "        # As we do not plan to train the model any further, we are calling\n",
        "        # init_sims(), which will make the model much more memory-efficient\n",
        "        self.model.init_sims(replace=True)\n",
        "\n",
        "    def aggregate_vectors(self, products):\n",
        "        product_vec = []\n",
        "        for i in products:\n",
        "            try:\n",
        "                product_vec.append(self.model[i])\n",
        "            except KeyError:\n",
        "                continue\n",
        "            \n",
        "        return np.mean(product_vec, axis=0)\n",
        "\n",
        "    def recommend(self, user_profile, topk=5):\n",
        "        \"\"\"\n",
        "        Given the user profile return a list of recommendation\n",
        "\n",
        "        Args:\n",
        "            user_profile: list of item ids visited/interacted by the user\n",
        "            topk: (optional) top-k recommendations\n",
        "        \"\"\"\n",
        "        rec = []\n",
        "        try:\n",
        "            vec = self.aggregate_vectors(user_profile)\n",
        "            # extract most similar products for the input vector\n",
        "            rec = self.model.wv.similar_by_vector(vec, topn= topk+1)[1:]\n",
        "        except KeyError:\n",
        "            rec = []\n",
        "\n",
        "        return rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm0ZQxhGHqtY",
        "outputId": "0169ac06-5f79-4729-eb6c-3d7e69e7d42a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Retail.xlsx  100%[===================>]  22.62M  10.7MB/s    in 2.1s    \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "!wget -q --show-progress https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\n",
        "\n",
        "df = pd.read_excel('Online Retail.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmLiT7JqHqtZ",
        "outputId": "d9235de5-face-4fce-da2f-a55f270487a2",
        "colab": {
          "referenced_widgets": [
            "c67c3bc470394dbc9374345f69804966",
            "a99361b1142540848001669faaa0d38c"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c67c3bc470394dbc9374345f69804966",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3935 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a99361b1142540848001669faaa0d38c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/437 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# remove missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert the StockCode to string datatype\n",
        "df['StockCode']= df['StockCode'].astype(str)\n",
        "\n",
        "# Check out the number of unique customers in our dataset\n",
        "customers = df[\"CustomerID\"].unique().tolist()\n",
        "\n",
        "# shuffle customer ID's\n",
        "import random\n",
        "random.shuffle(customers)\n",
        "\n",
        "# extract 90% of customer ID's\n",
        "customers_train = [customers[i] for i in range(round(0.9*len(customers)))]\n",
        "\n",
        "# split data into train and validation set\n",
        "train_df = df[df['CustomerID'].isin(customers_train)]\n",
        "validation_df = df[~df['CustomerID'].isin(customers_train)]\n",
        "\n",
        "# list to capture purchase history of the customers\n",
        "purchases_train = []\n",
        "\n",
        "# populate the list with the product codes\n",
        "from tqdm.notebook import tqdm\n",
        "for i in tqdm(customers_train):\n",
        "    temp = train_df[train_df[\"CustomerID\"] == i][\"StockCode\"].tolist()\n",
        "    purchases_train.append(temp)\n",
        "\n",
        "# list to capture purchase history of the customers\n",
        "purchases_val = []\n",
        "\n",
        "# populate the list with the product codes\n",
        "for i in tqdm(validation_df['CustomerID'].unique()):\n",
        "    temp = validation_df[validation_df[\"CustomerID\"] == i][\"StockCode\"].tolist()\n",
        "    purchases_val.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue1TTEu6Hqtb"
      },
      "outputs": [],
      "source": [
        "# Build word2vec Embeddings for Products\n",
        "# train word2vec model\n",
        "model = Prod2Vec(window=10, negative=5, size=100, min_count=2)\n",
        "model.fit(purchases_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikTF3OIWHqtc"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "products = train_df[[\"StockCode\", \"Description\"]]\n",
        "\n",
        "# remove duplicates\n",
        "products.drop_duplicates(inplace=True, subset='StockCode', keep=\"last\")\n",
        "\n",
        "# create product-ID and product-description dictionary\n",
        "products_dict = products.groupby('StockCode')['Description'].apply(list).to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3myFHSPHqtd",
        "outputId": "cf563364-dfa8-4bd3-df95-09c25e14f343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SET OF 3 BABUSHKA STACKING TINS']\n",
            " \n",
            "['EDWARDIAN HEART PHOTO FRAME', 0.3702189028263092]\n",
            "['SET OF 6 VINTAGE NOTELETS KIT', 0.34610092639923096]\n",
            "['FRENCH STYLE STORAGE JAR JAM', 0.3301945626735687]\n",
            "['BAG 500g SWIRLY MARBLES', 0.3177795708179474]\n",
            "['SPOTTY BUNTING', 0.30998745560646057]\n"
          ]
        }
      ],
      "source": [
        "random_sample = products.sample(1).values\n",
        "recommendations = [[products_dict[a][0], b] for a,b in model.recommend(user_profile=random_sample[:,0])]\n",
        "\n",
        "print(random_sample[:,1])\n",
        "print(' ')\n",
        "for rec in recommendations: print(rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypCZCxAwHqtd",
        "outputId": "f2e7cf2b-c663-4671-a613-d1051f38df7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SET OF 5 LUCKY CAT MAGNETS ' 'HEARTS GIFT TAPE'\n",
            " 'PAINTED YELLOW WOODEN DAISY' 'COLOURFUL FLOWER FRUIT BOWL'\n",
            " 'TUSCAN VILLA BIRD FEEDER']\n",
            " \n",
            "['PAINTED YELLOW WOODEN DAISY', 0.498282253742218]\n",
            "['HEARTS GIFT TAPE', 0.4829496443271637]\n",
            "['TUSCAN VILLA BIRD FEEDER', 0.34984883666038513]\n",
            "['STRAWBERRY RAFFIA FOOD COVER', 0.3352939486503601]\n",
            "['IVORY PAPER CUP CAKE CASES ', 0.3215782642364502]\n"
          ]
        }
      ],
      "source": [
        "random_sample = products.sample(5).values\n",
        "recommendations = [[products_dict[a][0], b] for a,b in model.recommend(user_profile=random_sample[:,0])]\n",
        "\n",
        "print(random_sample[:,1])\n",
        "print(' ')\n",
        "for rec in recommendations: print(rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arcx7O4kHqte"
      },
      "source": [
        "## Prod2Vec_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9f_07B5Hqtf"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class Prod2Vec_v2(ABC):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def train(self, items, iterations=15):\n",
        "        # Get the item ID and rating for each item for each unique user\n",
        "        x_train = [[str((x[\"sid\"], x[\"rating\"])) for x in y] for y in items]\n",
        "        self._model = self.train_embeddings(x_train, iterations=iterations)\n",
        "\n",
        "    def train_embeddings(\n",
        "        self,\n",
        "        sessions: list,\n",
        "        min_c: int = 3,\n",
        "        size: int = 48,\n",
        "        window: int = 5,\n",
        "        iterations: int = 15,\n",
        "        ns_exponent: float = 0.75,\n",
        "        is_debug: bool = True):\n",
        "        \"\"\"\n",
        "        Train CBOW to get product embeddings with sensible defaults\n",
        "        (https://arxiv.org/abs/2007.14906).\n",
        "        \"\"\"\n",
        "        model = gensim.models.Word2Vec(min_count=min_c,\n",
        "                                    size=size,\n",
        "                                    window=window,\n",
        "                                    iter=iterations,\n",
        "                                    ns_exponent=ns_exponent)\n",
        "\n",
        "        model.build_vocab(sessions)\n",
        "        model.init_sims(replace=True)\n",
        "        \n",
        "        return model.wv\n",
        "\n",
        "    def predict(self, prediction_input, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Predicts the top 10 similar items recommended for each user according\n",
        "        to the items that they've interacted and the ratings that they've given\n",
        "        :param prediction_input: a list of lists containing a dictionary for\n",
        "                                 each item interacted by that user\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        all_predictions = []\n",
        "        for items in prediction_input:\n",
        "            predictions = []\n",
        "            emb_vecs = []\n",
        "            for item in items:\n",
        "                emb_vec = self.get_vector(item)\n",
        "                if emb_vec:\n",
        "                    emb_vecs.append(emb_vec)\n",
        "            if emb_vecs:\n",
        "                # Calculate the average of all the latent vectors representing\n",
        "                # the items interacted by the user as is done in https://arxiv.org/abs/2007.14906\n",
        "                avg_emb_vec = np.mean(emb_vecs, axis=0)\n",
        "                nn_products = self.model.similar_by_vector(avg_emb_vec, topn=10)\n",
        "                for elem in nn_products:\n",
        "                    elem = ast.literal_eval(elem[0])\n",
        "                    predictions.append({\"sid\": elem[0], \"rating\": elem[1]})\n",
        "            all_predictions.append(predictions)\n",
        "        return all_predictions\n",
        "\n",
        "    def get_vector(self, x):\n",
        "        \"\"\"\n",
        "        Returns the latent vector that corresponds to the item ID and the rating\n",
        "        :param x:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        item = str((x[\"sid\"], x[\"rating\"]))\n",
        "        try:\n",
        "            return list(self.model.get_vector(item))\n",
        "        except Exception as e:\n",
        "            return []\n",
        "\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self._model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prod2Vec_v3"
      ],
      "metadata": {
        "id": "GaqGXZBjIASg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class Prod2Vec_v3:\n",
        "    \"\"\"\n",
        "    Implementation of the Prod2Vec skipgram model from\n",
        "    Grbovic Mihajlo, Vladan Radosavljevic, Nemanja Djuric, Narayan Bhamidipati, Jaikit Savla, Varun Bhagwan, and Doug Sharp.\n",
        "    \"E-commerce in your inbox: Product recommendations at scale.\"\n",
        "    In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,\n",
        "    pp. 1809-1818. ACM, 2015.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, min_count=2, size=100, window=5, decay_alpha=0.9, workers=4):\n",
        "        \"\"\"\n",
        "        :param min_count: (optional) the minimum item frequency. Items less frequent that min_count will be pruned\n",
        "        :param size: (optional) the size of the embeddings\n",
        "        :param window: (optional) the size of the context window\n",
        "        :param decay_alpha: (optional) the exponential decay factor used to discount the similarity scores for items\n",
        "                back in the user profile. Lower values mean higher discounting of past user interactions. Allows values in [0-1].\n",
        "        :param workers: (optional) the number of threads used for training\n",
        "        \"\"\"\n",
        "        self.min_count = min_count\n",
        "        self.size = size\n",
        "        self.window = window\n",
        "        self.decay_alpha = decay_alpha\n",
        "        self.workers = workers\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'Prod2VecRecommender(min_count={min_count}, ' \\\n",
        "               'size={size}, ' \\\n",
        "               'window={window}, ' \\\n",
        "               'decay_alpha={decay_alpha}, ' \\\n",
        "               'workers={workers})'.format(**self.__dict__)\n",
        "\n",
        "    def fit(self, train_data, seq_col='sequence'):\n",
        "        sequences = train_data[seq_col].values\n",
        "        self.model = gensim.models.Word2Vec(sequences,\n",
        "                                            min_count=self.min_count,\n",
        "                                            window=self.window,\n",
        "                                            hs=1,\n",
        "                                            size=self.size,\n",
        "                                            sg=1,\n",
        "                                            workers=self.workers)\n",
        "\n",
        "    def recommend(self, user_profile, user_id=None):\n",
        "        \"\"\"\n",
        "        Given the user profile return a list of recommendation\n",
        "        :param user_profile: the user profile as a list of item identifiers\n",
        "        :param user_id: (optional) the user id\n",
        "        :return: list of recommendations e.g. [([2], 0.875), ([6], 1.0)]\n",
        "        \"\"\"\n",
        "        user_profile = list(map(str, user_profile))\n",
        "        rec = []\n",
        "        try:\n",
        "            # iterate the user profile backwards\n",
        "            for i, item in enumerate(user_profile[::-1]):\n",
        "                ms = self.model.most_similar(positive=item)\n",
        "                # apply exponential decay to the similarity scores\n",
        "                decay = self.decay_alpha ** i\n",
        "                ms = [(x[0], decay * x[1]) for x in ms]\n",
        "                rec.extend(ms)\n",
        "            # sort items by similarity score\n",
        "            rec = sorted(rec, key=lambda x: -x[1])\n",
        "        except KeyError:\n",
        "            rec = []\n",
        "        return [([x[0]], x[1]) for x in rec]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_recommendation_list(recommendation):\n",
        "        return list(map(lambda x: x[0], recommendation))\n",
        "\n",
        "    @staticmethod\n",
        "    def get_recommendation_confidence_list(recommendation):\n",
        "        return list(map(lambda x: x[1], recommendation))"
      ],
      "metadata": {
        "id": "BZYSetfcIBa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example"
      ],
      "metadata": {
        "id": "qO-hpzxJIygO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from recohut.utils.data import load_dataset\n",
        "from recohut.utils.filters import filter_by_time, filter_top_k\n",
        "from recohut.utils.splitting import split_last_session_out\n",
        "from recohut.models.itempop import ItemPop_v2\n",
        "from recohut.evaluation.sequences import eval_seqreveal, eval_staticprofile\n",
        "from recohut.evaluation.sequences import eval_reclength, eval_profilelength"
      ],
      "metadata": {
        "id": "I07PSkJfGzr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_dataset('music30_sample')\n",
        "df.columns = ['session_id', 'user_id', 'item_id', 'ts', 'playtime']\n",
        "df['ts'] = pd.to_datetime(df['ts'], unit='s')\n",
        "\n",
        "# let's keep only the top-1k most popular items in the last month\n",
        "df = filter_by_time(df, last_months=1, ts_col='ts')\n",
        "df = filter_top_k(df, topk=1000, user_col='user_id', item_col='item_id', sess_col='session_id', ts_col='ts')\n",
        "\n",
        "train, test = split_last_session_out(df, user_col='user_id', sess_col='session_id', seq_col='sequence', time_col='ts')"
      ],
      "metadata": {
        "id": "kp1O_YBdUzU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Prod2Vec_v3()\n",
        "model.fit(train)"
      ],
      "metadata": {
        "id": "z1mrcDJmGxwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_seqreveal(train, test, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYmVeoTPxMMi",
        "outputId": "1fcd12dc-6310-4dfd-b8dd-0456847039b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2891 sequences available for evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2891/2891 [00:18<00:00, 154.10it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GIVEN_K': 1,\n",
              " 'LOOK_AHEAD': 1,\n",
              " 'MRR@10': 0.09646700449978074,\n",
              " 'Model': 'Prod2VecRecommender',\n",
              " 'Precision@10': 0.023950388764308123,\n",
              " 'Recall@10': 0.23162620325011596,\n",
              " 'STEP': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_staticprofile(train, test, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dyaMfKH7w61",
        "outputId": "527c0a82-e5bc-4c69-c211-bdfb5e136c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2891 sequences available for evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2891/2891 [00:01<00:00, 2624.12it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GIVEN_K': 1,\n",
              " 'LOOK_AHEAD': 'all',\n",
              " 'MRR@10': 0.1987120675550286,\n",
              " 'Model': 'Prod2VecRecommender',\n",
              " 'Precision@10': 0.10162573503977833,\n",
              " 'Recall@10': 0.19535189892426655,\n",
              " 'STEP': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_reclength(train, test, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhSTYXAT9wy1",
        "outputId": "89a786e4-5115-4c19-a626-19ce7bf13b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2891 sequences available for evaluation\n",
            "Evaluating recommendation lists with length: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2891/2891 [00:18<00:00, 152.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating recommendation lists with length: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2891/2891 [00:18<00:00, 153.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating recommendation lists with length: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2891/2891 [00:20<00:00, 142.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating recommendation lists with length: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2891/2891 [00:19<00:00, 148.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating recommendation lists with length: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2891/2891 [00:26<00:00, 109.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating recommendation lists with length: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2891/2891 [00:23<00:00, 122.21it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Figure size 360x360 with 1 Axes>,\n",
              " <Figure size 360x360 with 1 Axes>,\n",
              " <Figure size 360x360 with 1 Axes>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_profilelength(train, test, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUKbAYnytqVt",
        "outputId": "9413742b-927d-4412-b69a-071d23db3967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1164 sequences available for evaluation\n",
            "Evaluating profiles having length: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1164/1164 [00:00<00:00, 2759.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating profiles having length: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1164/1164 [00:00<00:00, 1442.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating profiles having length: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1164/1164 [00:01<00:00, 1114.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating profiles having length: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1164/1164 [00:01<00:00, 882.29it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Figure size 360x360 with 1 Axes>,\n",
              " <Figure size 360x360 with 1 Axes>,\n",
              " <Figure size 360x360 with 1 Axes>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> References\n",
        ">\n",
        "> 1. [https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-07-19-session-based-prod2vec-coveo.ipynb](https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-07-19-session-based-prod2vec-coveo.ipynb)\n",
        "> 2. [https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-06-11-recostep-session-based-recommender-using-word2vec.ipynb](https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-06-11-recostep-session-based-recommender-using-word2vec.ipynb)\n",
        "> 3. [https://github.com/mquad/sars_tutorial/blob/master/recommenders/Prod2VecRecommender.py](https://github.com/mquad/sars_tutorial/blob/master/recommenders/Prod2VecRecommender.py)\n",
        "> 4. [https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-04-24-rec-medium-word2vec.ipynb](https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-04-24-rec-medium-word2vec.ipynb)"
      ],
      "metadata": {
        "id": "SPOTFsObIkJB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R1JFlfZHqtg",
        "outputId": "740fc13c-94bc-40ad-d635-dd0c534c8db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Author: Sparsh A.\n",
            "\n",
            "Last updated: 2022-01-13 11:15:25\n",
            "\n",
            "recohut: 0.0.11\n",
            "\n",
            "Compiler    : GCC 7.5.0\n",
            "OS          : Linux\n",
            "Release     : 5.4.144+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "gensim    : 3.6.0\n",
            "IPython   : 5.5.0\n",
            "networkx  : 2.6.3\n",
            "json      : 2.0.9\n",
            "matplotlib: 3.2.2\n",
            "torch     : 1.10.0+cu111\n",
            "numpy     : 1.19.5\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "%reload_ext watermark\n",
        "%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p recohut"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "name": "models.prod2vec.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}