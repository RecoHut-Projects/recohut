{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN9QphGum4U0"
      },
      "outputs": [],
      "source": [
        "# default_exp models.afn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U03E3_Lm4U8"
      },
      "source": [
        "# AFN\n",
        "> A pytorch implementation of AFN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLpnIkxJm4VA"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from nbdev.showdoc import *\n",
        "from fastcore.nb_imports import *\n",
        "from fastcore.test import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## v1"
      ],
      "metadata": {
        "id": "GrvmdpQenLE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from recohut.models.layers.embedding import EmbeddingLayer\n",
        "from recohut.models.layers.common import MLP_Layer, LR_Layer\n",
        "\n",
        "from recohut.models.bases.ctr import CTRModel"
      ],
      "metadata": {
        "id": "l9hT_TEfnMy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class AFN(CTRModel):\n",
        "    def __init__(self, \n",
        "                 feature_map, \n",
        "                 model_id=\"AFN\",\n",
        "                 task=\"binary_classification\",\n",
        "                 learning_rate=1e-3, \n",
        "                 embedding_initializer=\"torch.nn.init.normal_(std=1e-4)\",\n",
        "                 embedding_dim=10, \n",
        "                 ensemble_dnn=True,\n",
        "                 dnn_hidden_units=[64, 64, 64], \n",
        "                 dnn_activations=\"ReLU\",\n",
        "                 dnn_dropout=0,\n",
        "                 afn_hidden_units=[64, 64, 64], \n",
        "                 afn_activations=\"ReLU\",\n",
        "                 afn_dropout=0,\n",
        "                 logarithmic_neurons=5,\n",
        "                 batch_norm=True,\n",
        "                 **kwargs):\n",
        "        super(AFN, self).__init__(feature_map, \n",
        "                                           model_id=model_id,\n",
        "                                           **kwargs)\n",
        "        self.num_fields = feature_map.num_fields\n",
        "        self.embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
        "        self.coefficient_W = nn.Linear(self.num_fields, logarithmic_neurons, bias=False)\n",
        "        self.dense_layer = MLP_Layer(input_dim=embedding_dim * logarithmic_neurons,\n",
        "                                     output_dim=1, \n",
        "                                     hidden_units=afn_hidden_units,\n",
        "                                     hidden_activations=afn_activations,\n",
        "                                     output_activation=None, \n",
        "                                     dropout_rates=afn_dropout, \n",
        "                                     batch_norm=batch_norm, \n",
        "                                     use_bias=True)\n",
        "        self.log_batch_norm = nn.BatchNorm1d(self.num_fields)\n",
        "        self.exp_batch_norm = nn.BatchNorm1d(logarithmic_neurons)\n",
        "        self.ensemble_dnn = ensemble_dnn\n",
        "        if ensemble_dnn:\n",
        "            self.embedding_layer2 = EmbeddingLayer(feature_map, \n",
        "                                                   embedding_dim, \n",
        "                                                   embedding_dropout)\n",
        "            self.dnn = MLP_Layer(input_dim=embedding_dim * self.num_fields,\n",
        "                                 output_dim=1, \n",
        "                                 hidden_units=dnn_hidden_units,\n",
        "                                 hidden_activations=dnn_activations,\n",
        "                                 output_activation=None, \n",
        "                                 dropout_rates=dnn_dropout, \n",
        "                                 batch_norm=batch_norm, \n",
        "                                 use_bias=True)\n",
        "            self.fc = nn.Linear(2, 1)\n",
        "        self.output_activation = self.get_final_activation(task)\n",
        "        self.init_weights(embedding_initializer=embedding_initializer)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        feature_emb = self.embedding_layer(inputs)\n",
        "        dnn_input = self.logarithmic_net(feature_emb)\n",
        "        afn_out = self.dense_layer(dnn_input)\n",
        "        if self.ensemble_dnn:\n",
        "            feature_emb_list2 = self.embedding_layer2(X)\n",
        "            concate_feature_emb = torch.cat(feature_emb_list2, dim=1)\n",
        "            dnn_out = self.dnn(concate_feature_emb)\n",
        "            y_pred = self.fc(torch.cat([afn_out, dnn_out], dim=-1))\n",
        "        else:\n",
        "            y_pred = afn_out\n",
        "\n",
        "        if self.output_activation is not None:\n",
        "            y_pred = self.output_activation(y_pred)\n",
        "        return y_pred\n",
        "\n",
        "    def logarithmic_net(self, feature_emb):\n",
        "        feature_emb = torch.abs(feature_emb)\n",
        "        feature_emb = torch.clamp(feature_emb, min=1e-5) # ReLU with min 1e-5 (better than 1e-7 suggested in paper)\n",
        "        log_feature_emb = torch.log(feature_emb) # element-wise log \n",
        "        log_feature_emb = self.log_batch_norm(log_feature_emb) # batch_size * num_fields * embedding_dim \n",
        "        logarithmic_out = self.coefficient_W(log_feature_emb.transpose(2, 1)).transpose(1, 2)\n",
        "        cross_out = torch.exp(logarithmic_out) # element-wise exp\n",
        "        cross_out = self.exp_batch_norm(cross_out)  # batch_size * logarithmic_neurons * embedding_dim\n",
        "        concat_out = torch.flatten(cross_out, start_dim=1)\n",
        "        return concat_out"
      ],
      "metadata": {
        "id": "bWVxCkXgFpqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example"
      ],
      "metadata": {
        "id": "ueSrnou3nj_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'model_id': 'AFN',\n",
        "              'data_dir': '/content/data',\n",
        "              'model_root': './checkpoints/',\n",
        "              'learning_rate': 1e-3,\n",
        "              'batch_norm': False,\n",
        "              'optimizer': 'adamw',\n",
        "              'task': 'binary_classification',\n",
        "              'loss': 'binary_crossentropy',\n",
        "              'metrics': ['logloss', 'AUC'],\n",
        "              'embedding_dim': 10,\n",
        "              'logarithmic_neurons': 1200,\n",
        "              'afn_hidden_units': [400, 400, 400],\n",
        "              'afn_activations': 'relu',\n",
        "              'afn_dropout': 0,\n",
        "              'ensemble_dnn': False,\n",
        "              'dnn_hidden_units': [400, 400, 400],\n",
        "              'dnn_activations': 'relu',\n",
        "              'dnn_dropout': 0,\n",
        "              'batch_size': 64,\n",
        "              'epochs': 3,\n",
        "              'shuffle': True,\n",
        "              'seed': 2019,\n",
        "              'use_hdf5': True,\n",
        "              'workers': 1,\n",
        "              'verbose': 0}"
      ],
      "metadata": {
        "id": "RF7l2_nfFpqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AFN(ds.dataset.feature_map, **params)"
      ],
      "metadata": {
        "id": "8ntD_jZmFpqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl_trainer(model, ds, max_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495,
          "referenced_widgets": [
            "4373d98cf97a4ae799ef2e9df8e77dc1",
            "e2305e4e825447bba68a6bc9ab7e9d10",
            "4f01842dd2784b41adb7d63b14e2bcb7",
            "2558d78af9b9465f8e7e3cba1154548e",
            "f7c7bc1e78b14e7b84d355264fb5d912",
            "b76afecb8e074633ad4039326746a10d",
            "b83575cd2dbc4be7924935c89c4d7be7",
            "6e33a115cf474e71860a30edbae1a7b6",
            "67f388453bfa45fda7774e1bfd3c7b64",
            "60966bd9ab0e4528a16476128ca7066e",
            "820e535d433149e881a906ccfa8428a4",
            "3fda041e4f4d4aacbf78af2ce4fbf3b8",
            "d390bd87318742da929d28c5433c229c",
            "eeba7de79ed046ddabfb0afdb8fc8750",
            "c53e4fd35fd14510880f09d696958898",
            "c0c59ea12c0f4cd2a77ff761336c7dc2",
            "3fde51f7a21144a492e0fa2a9d93d55a",
            "74b17e21460042fbbb0a2e95c6adb01c",
            "ecaa286b563b4fcfb0d0373f73dacf18",
            "f8b61fee16134bf78c823819cad0abd8",
            "4bf86f739b2c4d6f8bdfb00159ac967a",
            "bb7ebd3f8be24e4b95a689ecbaa442f1",
            "93d8a6e7b7184430b95e3556b1cde6e8",
            "6abd5e8ba6a64c99bcf20897aabbba2d",
            "d0153a7eb46e4d0fac7ca078f6d77de9",
            "fa08ce0e07fe4bb8b2428810e198951d",
            "b458d5aa0aec4c649d40281dee26fe19",
            "0d4c4f0803f9432d918b5ac2e570389b",
            "20c5af40bf6843f1bd13ed9ea8a11603",
            "b8c3b3f2dfd94882b0f3d27218c197bd",
            "4c11da8930d5411fa1a917dff9a36948",
            "201b8c842eb64339a198a08e79ffa013",
            "4cc8d186c72644d2976016da465e07f8"
          ]
        },
        "outputId": "cb6f8d2c-9e3d-4a37-8424-39b7b930ac89",
        "id": "3IMFgovJFpqY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "\n",
            "  | Name              | Type           | Params\n",
            "-----------------------------------------------------\n",
            "0 | embedding_layer   | EmbeddingLayer | 4.8 K \n",
            "1 | coefficient_W     | Linear         | 16.8 K\n",
            "2 | dense_layer       | MLP_Layer      | 5.1 M \n",
            "3 | log_batch_norm    | BatchNorm1d    | 28    \n",
            "4 | exp_batch_norm    | BatchNorm1d    | 2.4 K \n",
            "5 | output_activation | Sigmoid        | 0     \n",
            "-----------------------------------------------------\n",
            "5.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.1 M     Total params\n",
            "20.582    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4373d98cf97a4ae799ef2e9df8e77dc1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fda041e4f4d4aacbf78af2ce4fbf3b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93d8a6e7b7184430b95e3556b1cde6e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'Test Metrics': {'AUC': tensor(0.7091), 'logloss': tensor(0.3672)}}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Test Metrics': {'AUC': tensor(0.7091), 'logloss': tensor(0.3672)}}]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## v2"
      ],
      "metadata": {
        "id": "SNSOAhpAnCIA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgkQRElQm4VD"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from recohut.models.layers.common import FeaturesEmbedding, FeaturesLinear, MultiLayerPerceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10w7a6cAm4VF"
      },
      "outputs": [],
      "source": [
        "#exporti\n",
        "class LNN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A pytorch implementation of LNN layer\n",
        "    Input shape\n",
        "        - A 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n",
        "    Output shape\n",
        "        - 2D tensor with shape:``(batch_size,LNN_dim*embedding_size)``.\n",
        "    Arguments\n",
        "        - **in_features** : Embedding of feature.\n",
        "        - **num_fields**: int.The field size of feature.\n",
        "        - **LNN_dim**: int.The number of Logarithmic neuron.\n",
        "        - **bias**: bool.Whether or not use bias in LNN.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_fields, embed_dim, LNN_dim, bias=False):\n",
        "        super(LNN, self).__init__()\n",
        "        self.num_fields = num_fields\n",
        "        self.embed_dim = embed_dim\n",
        "        self.LNN_dim = LNN_dim\n",
        "        self.lnn_output_dim = LNN_dim * embed_dim\n",
        "        self.weight = torch.nn.Parameter(torch.Tensor(LNN_dim, num_fields))\n",
        "        if bias:\n",
        "            self.bias = torch.nn.Parameter(torch.Tensor(LNN_dim, embed_dim))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: Long tensor of size ``(batch_size, num_fields, embedding_size)``\n",
        "        \"\"\"\n",
        "        embed_x_abs = torch.abs(x) # Computes the element-wise absolute value of the given input tensor.\n",
        "        embed_x_afn = torch.add(embed_x_abs, 1e-7)\n",
        "        # Logarithmic Transformation\n",
        "        embed_x_log = torch.log1p(embed_x_afn) # torch.log1p and torch.expm1\n",
        "        lnn_out = torch.matmul(self.weight, embed_x_log)\n",
        "        if self.bias is not None:\n",
        "            lnn_out += self.bias\n",
        "        lnn_exp = torch.expm1(lnn_out)\n",
        "        output = F.relu(lnn_exp).contiguous().view(-1, self.lnn_output_dim)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class AFN_v2(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A pytorch implementation of AFN.\n",
        "    Reference:\n",
        "        Cheng W, et al. Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions, 2019.\n",
        "    \"\"\"\n",
        "    def __init__(self, field_dims, embed_dim, LNN_dim, mlp_dims, dropouts):\n",
        "        super().__init__()\n",
        "        self.num_fields = len(field_dims)\n",
        "        self.linear = FeaturesLinear(field_dims)    # Linear\n",
        "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)   # Embedding\n",
        "        self.LNN_dim = LNN_dim\n",
        "        self.LNN_output_dim = self.LNN_dim * embed_dim\n",
        "        self.LNN = LNN(self.num_fields, embed_dim, LNN_dim)\n",
        "        self.mlp = MultiLayerPerceptron(self.LNN_output_dim, mlp_dims, dropouts[0])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
        "        \"\"\"\n",
        "        embed_x = self.embedding(x)\n",
        "        lnn_out = self.LNN(embed_x)\n",
        "        x = self.linear(x) + self.mlp(lnn_out)\n",
        "        return torch.sigmoid(x.squeeze(1))"
      ],
      "metadata": {
        "id": "4cde6edOnEzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54qrW4fFm4VI"
      },
      "source": [
        "> **References**\n",
        "> - Cheng W, et al. Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions, 2019.\n",
        "> - https://github.com/rixwew/pytorch-fm/blob/master/torchfm/model/afn.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5rjBJnfm4VJ"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "%reload_ext watermark\n",
        "%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p recohut"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "name": "models.afn.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}