# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/utils/utils.data.ipynb (unless otherwise specified).

__all__ = ['list_datasets', 'load_dataset']

# Cell
import pandas as pd
import tempfile
import os

from .common_utils import download_url

# Cell
def list_datasets(top_n:int=None):
    """
    Retruns a pandas dataframe of all the available datasets and info

    Args:
        top_n (int): returns only top_n rows
    """
    url = 'https://docs.google.com/spreadsheets/d/1wY_83y2ltu6tzMNHFOQRNslrgb0VWH_wa7zP7lT6AvM/export?gid=0&format=csv'
    df = pd.read_csv(url, index_col=[0]).fillna('NA')
    if top_n:
        return df.head(top_n)
    return df

# Cell
def load_dataset(data_id, data_dir=None, log=False):
    dataset_list = list(list_datasets().index)
    assert data_id in dataset_list, f'data id not exist, available ids are {dataset_list}'

    if data_dir is None:
        data_dir = os.path.join(tempfile.gettempdir(), data_id)

    data_info = list_datasets().loc[data_id]
    path = download_url(data_info.url, data_dir, log=log)

    if data_info.format == 'parquet.snappy':
        df = pd.read_parquet(path)

    return df