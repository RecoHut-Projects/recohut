---

title: Amazon Beauty


keywords: fastai
sidebar: home_sidebar

summary: "Amazon Beauty Dataset."
description: "Amazon Beauty Dataset."
nb_path: "nbs/datasets/datasets.amazon_beauty.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/datasets/datasets.amazon_beauty.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AmazonBeautyDataset" class="doc_header"><code>class</code> <code>AmazonBeautyDataset</code><a href="https://github.com/RecoHut-Projects/recohut/tree/master/recohut/datasets/amazon_beauty.py#L16" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AmazonBeautyDataset</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <a href="/recohut/datasets.bases.sequential.html#SASRecDataset"><code>SASRecDataset</code></a></p>
</blockquote>
<p>An abstract class representing a :class:<a href="/recohut/datasets.base.html#Dataset"><code>Dataset</code></a>.</p>
<p>All datasets that represent a map from keys to data samples should subclass
it. All subclasses should overwrite :meth:<code>__getitem__</code>, supporting fetching a
data sample for a given key. Subclasses could also optionally overwrite
:meth:<code>__len__</code>, which is expected to return the size of the dataset by many
:class:<code>~torch.utils.data.Sampler</code> implementations and the default options
of :class:<code>~torch.utils.data.DataLoader</code>.</p>
<p>.. note::
  :class:<code>~torch.utils.data.DataLoader</code> by default constructs a index
  sampler that yields integral indices.  To make it work with a map-style
  dataset with non-integral indices/keys, a custom sampler must be provided.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AmazonBeautyDataModule" class="doc_header"><code>class</code> <code>AmazonBeautyDataModule</code><a href="https://github.com/RecoHut-Projects/recohut/tree/master/recohut/datasets/amazon_beauty.py#L37" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AmazonBeautyDataModule</code>(<strong>*<code>args</code></strong>:<code>Any</code>, <strong>**<code>kwargs</code></strong>:<code>Any</code>) :: <a href="/recohut/datasets.bases.sequential.html#SASRecDataModule"><code>SASRecDataModule</code></a></p>
</blockquote>
<p>A DataModule standardizes the training, val, test splits, data preparation and transforms. The main
advantage is consistent data splits, data preparation and transforms across models.</p>
<p>Example::</p>

<pre><code>class MyDataModule(LightningDataModule):
    def __init__(self):
        super().__init__()
    def prepare_data(self):
        # download, split, etc...
        # only called on 1 GPU/TPU in distributed
    def setup(self, stage):
        # make assignments here (val/train/test split)
        # called on every process in DDP
    def train_dataloader(self):
        train_split = Dataset(...)
        return DataLoader(train_split)
    def val_dataloader(self):
        val_split = Dataset(...)
        return DataLoader(val_split)
    def test_dataloader(self):
        test_split = Dataset(...)
        return DataLoader(test_split)
    def teardown(self):
        # clean up after fit or test
        # called on every process in DDP

</code></pre>
<p>A DataModule implements 6 key methods:</p>
<ul>
<li><strong>prepare_data</strong> (things to do on 1 GPU/TPU not on every GPU/TPU in distributed mode).</li>
<li><strong>setup</strong>  (things to do on every accelerator in distributed mode).</li>
<li><strong>train_dataloader</strong> the training dataloader.</li>
<li><strong>val_dataloader</strong> the val dataloader(s).</li>
<li><strong>test_dataloader</strong> the test dataloader(s).</li>
<li><strong>teardown</strong> (things to do on every accelerator in distributed mode when finished)</li>
</ul>
<p>This allows you to share a full dataset without explaining how to download, split, transform, and process the data</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Example</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Args</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;/content/data&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_len</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="o">=</span> <span class="mf">0.2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">Args</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dm</span> <span class="o">=</span> <span class="n">AmazonBeautyDataModule</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
<span class="n">dm</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Downloading https://github.com/RecoHut-Datasets/amazon_beauty/raw/v1/amazon-ratings.zip
Extracting /content/data/raw/amazon-ratings.zip
Processing...
Done!
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dm</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[tensor([394, 421, 256, 119, 320, 434,  30, 431,  54,  67, 415, 277, 254, 321,
        290,  95, 206, 275, 391, 463, 323, 105, 399, 288,  14, 120, 147,  47,
         82, 437, 412, 184]), tensor([[   0,    0,    0,  ..., 4183, 1750,  690],
        [   0,    0,    0,  ..., 3153, 5408, 5208],
        [   0,    0,    0,  ..., 1905, 5639,  614],
        ...,
        [   0,    0,    0,  ..., 4549, 1287,  282],
        [   0,    0,    0,  ..., 3507, 5045, 2892],
        [   0,    0,    0,  ...,  279, 4246, 2803]]), tensor([[   0,    0,    0,  ..., 1750,  690, 1826],
        [   0,    0,    0,  ..., 5408, 5208, 2940],
        [   0,    0,    0,  ..., 5639,  614, 1146],
        ...,
        [   0,    0,    0,  ..., 1287,  282, 1651],
        [   0,    0,    0,  ..., 5045, 2892, 1006],
        [   0,    0,    0,  ..., 4246, 2803,  737]]), tensor([[   0,    0,    0,  ..., 3246, 5423, 3585],
        [   0,    0,    0,  ...,   89, 1891,   60],
        [   0,    0,    0,  ..., 3051, 5472, 1113],
        ...,
        [   0,    0,    0,  ..., 1258, 3876, 5313],
        [   0,    0,    0,  ..., 2543, 4867, 3729],
        [   0,    0,    0,  ..., 4550,  928, 5276]]), tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0]])]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

