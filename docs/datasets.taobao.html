---

title: Taobao Dataset


keywords: fastai
sidebar: home_sidebar

summary: "Implementation of Taobao dataset in Pytorch lightning."
description: "Implementation of Taobao dataset in Pytorch lightning."
nb_path: "nbs/datasets/datasets.taobao.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/datasets/datasets.taobao.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TaobaoDataset" class="doc_header"><code>class</code> <code>TaobaoDataset</code><a href="https://github.com/RecoHut-Projects/recohut/tree/master/recohut/datasets/taobao.py#L12" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TaobaoDataset</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <a href="/recohut/datasets.bases.ctr.html#CTRDataset"><code>CTRDataset</code></a></p>
</blockquote>
<p>An abstract class representing a :class:<a href="/recohut/datasets.base.html#Dataset"><code>Dataset</code></a>.</p>
<p>All datasets that represent a map from keys to data samples should subclass
it. All subclasses should overwrite :meth:<code>__getitem__</code>, supporting fetching a
data sample for a given key. Subclasses could also optionally overwrite
:meth:<code>__len__</code>, which is expected to return the size of the dataset by many
:class:<code>~torch.utils.data.Sampler</code> implementations and the default options
of :class:<code>~torch.utils.data.DataLoader</code>.</p>
<p>.. note::
  :class:<code>~torch.utils.data.DataLoader</code> by default constructs a index
  sampler that yields integral indices.  To make it work with a map-style
  dataset with non-integral indices/keys, a custom sampler must be provided.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TaobaoDataModule" class="doc_header"><code>class</code> <code>TaobaoDataModule</code><a href="https://github.com/RecoHut-Projects/recohut/tree/master/recohut/datasets/taobao.py#L51" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TaobaoDataModule</code>(<strong>*<code>args</code></strong>:<code>Any</code>, <strong>**<code>kwargs</code></strong>:<code>Any</code>) :: <a href="/recohut/datasets.bases.ctr.html#CTRDataModule"><code>CTRDataModule</code></a></p>
</blockquote>
<p>A DataModule standardizes the training, val, test splits, data preparation and transforms. The main
advantage is consistent data splits, data preparation and transforms across models.</p>
<p>Example::</p>

<pre><code>class MyDataModule(LightningDataModule):
    def __init__(self):
        super().__init__()
    def prepare_data(self):
        # download, split, etc...
        # only called on 1 GPU/TPU in distributed
    def setup(self, stage):
        # make assignments here (val/train/test split)
        # called on every process in DDP
    def train_dataloader(self):
        train_split = Dataset(...)
        return DataLoader(train_split)
    def val_dataloader(self):
        val_split = Dataset(...)
        return DataLoader(val_split)
    def test_dataloader(self):
        test_split = Dataset(...)
        return DataLoader(test_split)
    def teardown(self):
        # clean up after fit or test
        # called on every process in DDP

</code></pre>
<p>A DataModule implements 6 key methods:</p>
<ul>
<li><strong>prepare_data</strong> (things to do on 1 GPU/TPU not on every GPU/TPU in distributed mode).</li>
<li><strong>setup</strong>  (things to do on every accelerator in distributed mode).</li>
<li><strong>train_dataloader</strong> the training dataloader.</li>
<li><strong>val_dataloader</strong> the val dataloader(s).</li>
<li><strong>test_dataloader</strong> the test dataloader(s).</li>
<li><strong>teardown</strong> (things to do on every accelerator in distributed mode when finished)</li>
</ul>
<p>This allows you to share a full dataset without explaining how to download, split, transform, and process the data</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;model_id&#39;</span><span class="p">:</span> <span class="s1">&#39;DCN_demo&#39;</span><span class="p">,</span>
              <span class="s1">&#39;data_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;/content/data&#39;</span><span class="p">,</span>
              <span class="s1">&#39;model_root&#39;</span><span class="p">:</span> <span class="s1">&#39;./checkpoints/&#39;</span><span class="p">,</span>
              <span class="s1">&#39;dnn_hidden_units&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
              <span class="s1">&#39;dnn_activations&#39;</span><span class="p">:</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
              <span class="s1">&#39;crossing_layers&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
              <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
              <span class="s1">&#39;net_dropout&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
              <span class="s1">&#39;batch_norm&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
              <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adamw&#39;</span><span class="p">,</span>
              <span class="s1">&#39;task&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_classification&#39;</span><span class="p">,</span>
              <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;logloss&#39;</span><span class="p">,</span> <span class="s1">&#39;AUC&#39;</span><span class="p">],</span>
              <span class="s1">&#39;embedding_dim&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
              <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
              <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
              <span class="s1">&#39;shuffle&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
              <span class="s1">&#39;seed&#39;</span><span class="p">:</span> <span class="mi">2019</span><span class="p">,</span>
              <span class="s1">&#39;use_hdf5&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
              <span class="s1">&#39;workers&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
              <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span> <span class="o">=</span> <span class="n">TaobaoDataModule</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
<span class="n">ds</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">ds</span><span class="o">.</span><span class="n">setup</span><span class="p">()</span>

<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">ds</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[tensor([[20., 96.,  1., 18., 94., 93., 63.,  9.,  9.,  2.,  2.,  2.,  1.,  1.],
        [18., 78.,  1., 43., 76., 75.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  1.],
        [ 5., 52.,  1.,  1., 51., 51.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
        [ 5., 35.,  1.,  7.,  2.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
        [ 1., 26.,  1., 23., 26., 26., 22.,  1.,  1.,  1.,  1.,  0.,  1.,  1.],
        [20., 75.,  1., 42., 73., 72.,  7.,  9.,  9.,  2.,  2.,  2.,  1.,  1.],
        [ 2., 17.,  1.,  2., 17., 17., 16.,  1.,  2.,  1.,  2.,  0.,  1.,  1.],
        [15., 55.,  2., 10., 53., 53., 41.,  6.,  7.,  1.,  5.,  1.,  1.,  1.],
        [ 3., 72.,  1., 40., 70., 69., 53.,  1.,  4.,  1.,  3.,  0.,  1.,  1.],
        [ 3., 84.,  1., 45., 82., 81., 57.,  1.,  4.,  1.,  3.,  0.,  1.,  1.],
        [ 1., 20.,  1.,  9., 20., 20.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  1.],
        [ 3., 81.,  1.,  6., 79., 78.,  0.,  1.,  4.,  1.,  3.,  0.,  1.,  1.],
        [ 1., 27.,  1.,  9., 27., 27., 23.,  1.,  1.,  1.,  1.,  0.,  1.,  1.],
        [22., 66.,  2., 16., 64., 63., 49.,  4.,  3.,  1.,  4.,  1.,  1.,  1.],
        [ 2., 15.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  2.,  0.,  1.,  1.],
        [19., 83.,  1., 18., 81., 80., 56.,  8.,  1.,  1.,  1.,  2.,  1.,  2.],
        [17., 98.,  1., 19., 96., 95., 65.,  7.,  3.,  1.,  4.,  2.,  2.,  1.],
        [11., 32.,  2., 25., 32., 32., 26.,  2.,  1.,  1.,  1.,  1.,  1.,  1.],
        [ 8., 13.,  2.,  1., 14.,  2.,  3.,  2.,  1.,  1.,  1.,  1.,  1.,  1.],
        [ 4., 80.,  2., 44., 78., 77.,  4.,  3.,  2.,  1.,  2.,  1.,  1.,  1.],
        [ 5., 62.,  1.,  7., 60., 60., 46.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
        [ 2., 18.,  1.,  3., 18., 18.,  0.,  1.,  2.,  1.,  2.,  0.,  1.,  1.],
        [12., 56.,  1.,  5., 54., 54.,  0.,  5.,  8.,  2.,  5.,  1.,  1.,  1.],
        [ 6., 48.,  1., 34., 47., 47., 37.,  1.,  6.,  2.,  1.,  0.,  1.,  1.],
        [10., 42.,  2., 31., 41., 41., 34.,  1.,  1.,  1.,  1.,  0.,  1.,  1.],
        [ 4., 86.,  2., 47., 84., 83.,  0.,  3.,  2.,  1.,  2.,  1.,  1.,  1.],
        [ 3., 77.,  1.,  1., 75., 74., 55.,  1.,  4.,  1.,  3.,  0.,  1.,  1.],
        [21.,  4.,  2., 20.,  5.,  6., 10.,  1.,  7.,  1.,  5.,  0.,  1.,  1.],
        [16., 79.,  1.,  4., 77., 76.,  0.,  1.,  5.,  2.,  3.,  0.,  2.,  1.],
        [ 4., 99.,  2., 10., 97., 96.,  8.,  3.,  2.,  1.,  2.,  1.,  1.,  1.],
        [ 6., 47.,  1., 33., 46., 46., 36.,  1.,  6.,  2.,  1.,  0.,  1.,  1.],
        [ 5., 61.,  1.,  1., 59., 59.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
        [11., 58.,  2.,  1., 56., 56., 43.,  2.,  1.,  1.,  1.,  1.,  1.,  1.],
        [12., 38.,  1., 28., 37., 37., 30.,  5.,  8.,  2.,  5.,  1.,  1.,  1.],
        [23., 95.,  2.,  2., 93., 92.,  6.,  1.,  6.,  2.,  1.,  1.,  1.,  1.],
        [ 2., 14.,  1.,  5., 15., 15.,  0.,  1.,  2.,  1.,  2.,  0.,  1.,  1.],
        [ 1.,  7.,  1., 13.,  8.,  9., 13.,  1.,  1.,  1.,  1.,  0.,  1.,  1.],
        [19., 74.,  1.,  6., 72., 71., 54.,  8.,  1.,  1.,  1.,  2.,  1.,  2.],
        [17., 90.,  1., 19., 88., 87., 60.,  7.,  3.,  1.,  4.,  2.,  2.,  1.],
        [ 4., 94.,  2., 17., 92., 91., 62.,  3.,  2.,  1.,  2.,  1.,  1.,  1.],
        [ 9., 30.,  1., 24., 30., 30., 24.,  2.,  1.,  1.,  1.,  1.,  1.,  1.],
        [14., 41.,  1.,  4., 40., 40., 33.,  1.,  3.,  1.,  4.,  0.,  3.,  1.],
        [23., 69.,  2.,  2., 67., 66.,  6.,  1.,  6.,  2.,  1.,  1.,  1.,  1.],
        [ 2., 28.,  1.,  6., 28., 28.,  0.,  1.,  2.,  1.,  2.,  0.,  1.,  1.],
        [ 5., 53.,  1.,  7.,  2.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
        [ 8., 21.,  2.,  1., 21., 21., 18.,  2.,  1.,  1.,  1.,  1.,  1.,  1.],
        [ 7.,  5.,  2., 12.,  6.,  7., 11.,  4.,  3.,  1.,  4.,  1.,  1.,  1.],
        [ 6., 57.,  1.,  2., 55., 55., 42.,  1.,  6.,  2.,  1.,  0.,  1.,  1.],
        [18., 70.,  1., 38., 68., 67., 51.,  1.,  1.,  1.,  1.,  0.,  1.,  1.],
        [ 5., 43.,  1.,  1., 42., 42., 35.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
        [ 2., 25.,  1.,  1., 25., 25., 21.,  1.,  2.,  1.,  2.,  0.,  1.,  1.],
        [14., 40.,  1., 30., 39., 39., 32.,  1.,  3.,  1.,  4.,  0.,  3.,  1.],
        [ 6., 51.,  1.,  2., 50., 50., 40.,  1.,  6.,  2.,  1.,  0.,  1.,  1.],
        [ 3., 63.,  1.,  1., 61.,  2.,  3.,  1.,  4.,  1.,  3.,  0.,  1.,  1.],
        [24., 68.,  1., 37., 66., 65., 50.,  1.,  4.,  1.,  3.,  0.,  2.,  1.],
        [ 4., 87.,  2., 11., 85., 84., 59.,  3.,  2.,  1.,  2.,  1.,  1.,  1.],
        [ 8.,  9.,  2.,  1., 10., 11.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.],
        [ 4., 85.,  2., 46., 83., 82., 58.,  3.,  2.,  1.,  2.,  1.,  1.,  1.],
        [ 1.,  2.,  1.,  8.,  4.,  5.,  9.,  1.,  1.,  1.,  1.,  0.,  1.,  1.],
        [ 7., 22.,  2., 12., 22., 22.,  0.,  4.,  3.,  1.,  4.,  1.,  1.,  1.],
        [13., 39.,  1., 29., 38., 38., 31.,  1.,  5.,  2.,  3.,  0.,  3.,  1.],
        [13., 50.,  1., 36., 49., 49., 39.,  1.,  5.,  2.,  3.,  0.,  3.,  1.],
        [ 5., 36.,  1.,  7., 35., 35., 28.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
        [13., 60.,  1.,  2., 58., 58., 45.,  1.,  5.,  2.,  3.,  0.,  3.,  1.]],
       dtype=torch.float64), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:74: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.
  &#34;DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.&#34;
Processing...
Done!
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

